{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KabDes/Sample-code-on-malaria-modeling-using-CNN/blob/main/Malaria_Diagnosis_using_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_hxzrVpanrY"
      },
      "source": [
        "# Deep Learning for Malaria Diagnosis \n",
        "**Instructor:** [Dr. Habiboulaye Amadou-Boubacar](https://www.linkedin.com/in/habiboulaye-amadou-boubacar-8b153710)  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DyHvXlda9rH"
      },
      "source": [
        "Malaria is an infectuous disease caused by parasites that are transmitted to people through the bites of infected female Anopheles mosquitoes.\n",
        "\n",
        "The Malaria burden with some key figures:\n",
        "<font color='red'>\n",
        "* More than 219 million cases\n",
        "* Over 430 000 deaths in 2017 (Mostly: children & pregnants)\n",
        "* 80% in 15 countries of Africa & India\n",
        "  </font>\n",
        "\n",
        "![MalariaBurd](https://github.com/habiboulaye/ai-labs/blob/master/malaria-diagnosis/doc-images/MalariaBurden.png?raw=1)\n",
        "\n",
        "The malaria diagnosis is performed using blood test:\n",
        "* Collect patient blood smear \n",
        "* Microscopic visualisation of the parasit\n",
        "\n",
        "![MalariaDiag](https://github.com/habiboulaye/ai-labs/blob/master/malaria-diagnosis/doc-images/MalariaDiag.png?raw=1)\n",
        "  \n",
        "Main issues related to traditional diagnosis: \n",
        "<font color='#ed7d31'>\n",
        "* resource-constrained regions \n",
        "* time needed and delays\n",
        "* diagnosis accuracy and cost\n",
        "</font>\n",
        "\n",
        "The objective of this notebook is to apply modern deep learning techniques to perform medical image analysis for malaria diagnosis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5qBTeqkrJ88"
      },
      "source": [
        "*This notebook is inspired by works of (Sivaramakrishnan Rajaraman  et al., 2018), (Adrian Rosebrock, 2018) and (Jason Brownlee, 2019)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4K5rb4bmdMRf"
      },
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdpDuJOle5sc"
      },
      "source": [
        "* **Useful infos**: *https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxaLbRUnYWTm"
      },
      "outputs": [],
      "source": [
        "#Mount the local drive project_forder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "!ls \"/content/drive/My Drive/Colab Notebooks/10xDS/Projects/malaria-diagnosis/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIfORUX7ccHI"
      },
      "outputs": [],
      "source": [
        "# Use GPU: Please check if the outpout is '/device:GPU:0'\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "tf.test.gpu_device_name()\n",
        "#from tensorflow.python.client import device_lib\n",
        "#device_lib.list_local_devices()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gp1o6Cd7dV6Z"
      },
      "source": [
        "## Populating namespaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4Ph8e1uojEC"
      },
      "outputs": [],
      "source": [
        "# Importing basic libraries\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "from matplotlib import pyplot\n",
        "from matplotlib.image import imread\n",
        "%matplotlib inline\n",
        "\n",
        "# Importing the Keras libraries and packages\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Convolution2D as Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOvmLtdRgSIb"
      },
      "outputs": [],
      "source": [
        "# Define the useful paths for data accessibility\n",
        "ai_project = '.' #\"/content/drive/My Drive/Colab Notebooks/ai-labs/malaria-diagnosis\"\n",
        "cell_images_dir = os.path.join(ai_project,'cell_images')\n",
        "training_path = os.path.join(ai_project,'train')\n",
        "testing_path = os.path.join(ai_project,'test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11DKlCJcj31w"
      },
      "source": [
        "## Prepare DataSet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "midATIuUq7H7"
      },
      "source": [
        "### *Download* DataSet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCT2ogQdeHPW"
      },
      "outputs": [],
      "source": [
        "# Download the data in the allocated google cloud-server. If already down, turn downloadData=False\n",
        "downloadData = True\n",
        "if downloadData == True:\n",
        "  indrive = False\n",
        "  if indrive == True:\n",
        "    !wget https://data.lhncbc.nlm.nih.gov/public/Malaria/cell_images.zip -P \"/content/drive/My Drive/Colab Notebooks/ai-labs/malaria-diagnosis\"\n",
        "    !unzip \"/content/drive/My Drive/Colab Notebooks/ai-labs/malaria-diagnosis/cell_images.zip\" -d \"/content/drive/My Drive/Colab Notebooks/ai-labs/malaria-diagnosis/\"\n",
        "    !ls \"/content/drive/My Drive/Colab Notebooks/ai-labs/malaria-diagnosis\"\n",
        "  else: #incloud google server\n",
        "    !rm -rf cell_images.*\n",
        "    !wget https://data.lhncbc.nlm.nih.gov/public/Malaria/cell_images.zip\n",
        "    !unzip cell_images.zip >/dev/null 2>&1\n",
        "    !ls "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNw0Rvv7U2vK"
      },
      "source": [
        "### Visualize cell images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-18T23:00:47.131389Z",
          "start_time": "2019-07-18T23:00:45.667288Z"
        },
        "id": "E3fVApLxU2vL"
      },
      "outputs": [],
      "source": [
        "# Visualize some samples (randomly selected) of blood smears from healthy patients \n",
        "N_samples = 10\n",
        "uninfected_dir = os.path.join(cell_images_dir,'Uninfected')\n",
        "uninfected_samples = random.sample(os.listdir(uninfected_dir), N_samples)\n",
        "pyplot.figure(figsize=(15,3))\n",
        "print(\"{} Uninfected images: view of {} samples\".format(len(os.listdir(uninfected_dir)), N_samples))\n",
        "i = 0\n",
        "while i < N_samples: # in random.sample(os.listdir(parasitized_dir), 6):\n",
        "    pyplot.subplot(1,N_samples,1+i)\n",
        "    img_uninfected = imread(os.path.join(uninfected_dir, uninfected_samples[i]))\n",
        "    pyplot.imshow(img_uninfected)\n",
        "    i+=1\n",
        "print(img_uninfected.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-18T23:00:48.569843Z",
          "start_time": "2019-07-18T23:00:47.135638Z"
        },
        "id": "5bivLkZJU2vQ"
      },
      "outputs": [],
      "source": [
        "# Visualize some samples (randomly selected) of blood smears from patients falciparum-infected \n",
        "print(\"{} Parasitized images: view of {} samples\".format(len(os.listdir(uninfected_dir)), N_samples))\n",
        "parasitized_dir = os.path.join(cell_images_dir,'Parasitized')\n",
        "parasitized_samples = random.sample(os.listdir(parasitized_dir), N_samples)\n",
        "pyplot.figure(figsize=(15,3))\n",
        "i = 0\n",
        "while i < N_samples: # in random.sample(os.listdir(parasitized_dir), 6):\n",
        "    pyplot.subplot(1,N_samples,1+i)\n",
        "    #Not Implemented\n",
        "    img_parasitized = imread(os.path.join(parasitized_dir, parasitized_samples[i]))\n",
        "    pyplot.imshow(img_parasitized)\n",
        "    i+=1\n",
        "print(img_parasitized.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHUcNb15U2vT"
      },
      "source": [
        "### Split train-test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aq6VmARGVZLV"
      },
      "outputs": [],
      "source": [
        "def create_train_test_data(class_name, train_split = 0.8):\n",
        "    '''\n",
        "      #Create a function create_train_test_data to split data into \n",
        "      #training and testing sets with respectives proportion 80%, 20%\n",
        "      #--Train (@training_path)\n",
        "          #--Parasitized\n",
        "          #--Uninfected\n",
        "      #--Test (@training_path)\n",
        "          #--Parasitized\n",
        "          #--Uninfected\n",
        "      @class_name: 'Parasitized' or 'Uninfected'\n",
        "      @train_split: eg. 80% train 20% test\n",
        "    '''    \n",
        "    train_class_path = os.path.join(training_path,class_name)  \n",
        "    test_class_path = os.path.join(testing_path,class_name)\n",
        "\n",
        "    class_img_names = [img for img in os.listdir(os.path.join(cell_images_dir, class_name))]\n",
        "    random.seed(42)\n",
        "    random.shuffle(class_img_names)\n",
        "\n",
        "    # compute the training and testing split\n",
        "    i = int(len(class_img_names) * train_split)\n",
        "    train_class_img_names = class_img_names[:i]\n",
        "    test_class_img_names = class_img_names[i:]\n",
        "\n",
        "    def copy_imgs(learn_class_img_names, learn_class_path):\n",
        "        if not os.path.exists(learn_class_path):\n",
        "            os.makedirs(learn_class_path)\n",
        "        for img in learn_class_img_names:\n",
        "            p_orig = os.path.join(cell_images_dir,class_name,img) \n",
        "            p_dest = os.path.join(learn_class_path,img) \n",
        "            shutil.copy2(p_orig, p_dest)\n",
        "\n",
        "    copy_imgs(train_class_img_names, train_class_path)\n",
        "    copy_imgs(test_class_img_names, test_class_path)\n",
        "\n",
        "SplitTrainTest = True\n",
        "if SplitTrainTest == True:\n",
        "    #Not Implemented\n",
        "    if os.path.exists(training_path): shutil.rmtree(training_path)\n",
        "    if os.path.exists(testing_path): shutil.rmtree(testing_path)\n",
        "\n",
        "    # Create the training and testing subset for Parasitized class\n",
        "    create_train_test_data('Parasitized', train_split=0.8)\n",
        "    \n",
        "    # Create the training and testing subset for Uninfected class\n",
        "    create_train_test_data('Uninfected', train_split=0.8)\n",
        "    \n",
        "# Check if training_path and testing_path folders with both classes are created\n",
        "!ls train/ test/\n",
        "# Check the number of files in the Parasitized training set\n",
        "!ls train/Parasitized | wc -l\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1LUJGE9U2vW"
      },
      "source": [
        "## Baseline CNN Model\n",
        "Define a basic ConvNet defined with ConvLayer: Conv2D => MaxPooling2D followed by Flatten => Dense => Dense(output)\n",
        "\n",
        "![ConvNet](https://github.com/habiboulaye/ai-labs/blob/master/malaria-diagnosis/doc-images/ConvNet.png?raw=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-19T13:20:02.960282Z",
          "start_time": "2019-07-19T13:20:02.952429Z"
        },
        "id": "vFjwvZFuU2vX"
      },
      "outputs": [],
      "source": [
        "#single convolutional layer with 32 filters followed by a max pooling layer.\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "BatchSize = 32\n",
        "xy_shape = 64\n",
        "n_epochs = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-19T13:20:03.383789Z",
          "start_time": "2019-07-19T13:20:03.372097Z"
        },
        "id": "n0XSkJNKU2vZ"
      },
      "outputs": [],
      "source": [
        "# define cnn model\n",
        "def simple_cnn_model():\n",
        "    model = Sequential()\n",
        "    # 1 ConvLayer\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(xy_shape, xy_shape, 3)))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    # Flatten and Dense layers\n",
        "    model.add(Flatten())\n",
        "    # Add a Dense (Fully Connected) layer with 128 neurons with 'relu' activation with a kernel_initializer='he_uniform'\n",
        "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "    # Add a Dense output layer with 1 neuron and activated by 'sigmoid'\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    # compile model\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-19T13:20:07.051451Z",
          "start_time": "2019-07-19T13:20:05.567290Z"
        },
        "id": "oY71FelrU2vb"
      },
      "outputs": [],
      "source": [
        "# Instanciate a data generator to fit the model\n",
        "dataGen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "# prepare iterators\n",
        "train_gen = dataGen.flow_from_directory(training_path,class_mode=\"binary\",target_size=(xy_shape, xy_shape),\n",
        "                                         batch_size=BatchSize)\n",
        "test_gen = dataGen.flow_from_directory(testing_path,class_mode=\"binary\",target_size=(xy_shape, xy_shape),\n",
        "                                        batch_size=BatchSize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-18T23:19:55.478410Z",
          "start_time": "2019-07-18T23:01:12.865662Z"
        },
        "id": "b6ypPV-eU2ve"
      },
      "outputs": [],
      "source": [
        "# Instanciate and train the model\n",
        "conv_net1 = simple_cnn_model()\n",
        "conv_net1_loss_acc_records = conv_net1.fit_generator(train_gen, steps_per_epoch=len(train_gen),validation_data=test_gen, validation_steps=len(test_gen), \n",
        "                              epochs=n_epochs, verbose=1, use_multiprocessing=True)#, workers=) #validation_freq=[1,2,5,10,15,20],"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-19T13:20:56.619035Z",
          "start_time": "2019-07-19T13:20:56.216075Z"
        },
        "id": "L4ji4dfcU2vl"
      },
      "outputs": [],
      "source": [
        "# This function is defined to visualise loss and accuracy\n",
        "def assess_performance(history):\n",
        "    pyplot.figure(figsize=(15,3))\n",
        "    # plot loss\n",
        "    pyplot.subplot(121)\n",
        "    pyplot.title('Cross Entropy Loss')\n",
        "    pyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "    pyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "    # plot accuracy\n",
        "    pyplot.subplot(122)\n",
        "    pyplot.title('Classification Accuracy')\n",
        "    pyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "    pyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "\n",
        "#assess_performance(conv_net1_loss_acc_records)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-19T13:21:28.494777Z",
          "start_time": "2019-07-19T13:21:05.270097Z"
        },
        "id": "XCUSdOcEU2vo"
      },
      "outputs": [],
      "source": [
        "# evaluate model\n",
        "_, acc = conv_net1.evaluate_generator(test_gen, steps=len(test_gen), use_multiprocessing=True, verbose=0)\n",
        "print('> %.3f' % (acc * 100.0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQPM3U9XU2vr"
      },
      "source": [
        "### Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-19T22:42:23.068905Z",
          "start_time": "2019-07-19T22:42:21.359267Z"
        },
        "id": "WRYA8tt6U2vs"
      },
      "outputs": [],
      "source": [
        "# Use data augmentation techniques to generate more variational data and improve the performance\n",
        "# data augmentation is a technique that can be used to artificially expand the size of a training dataset by creating modified versions of images in the dataset.\n",
        "# Training deep learning neural network models on more data can result in more skillful models, and the augmentation techniques can create variations of the images that can improve the ability of the fit models to generalize what they have learned to new images.\n",
        "# the training dataset will be augmented with small (10%) random horizontal and vertical shifts and random horizontal flips that create a mirror image of a photo. Photos in both the train and test steps will have their pixel values scaled in the same way.\n",
        "\n",
        "trainAug = ImageDataGenerator(\n",
        "    rescale=1/255.0,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.05,\n",
        "    width_shift_range=0.05,\n",
        "    height_shift_range=0.05,\n",
        "    shear_range=0.05,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\")\n",
        "# Keep\n",
        "# dataGen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "\n",
        "# Generate the new training data using augmentation and testing data \n",
        "train_aug = trainAug.flow_from_directory(training_path,class_mode=\"binary\",target_size=(xy_shape, xy_shape),\n",
        "                                         batch_size=BatchSize)\n",
        "test_gen = dataGen.flow_from_directory(testing_path,class_mode=\"binary\",target_size=(xy_shape, xy_shape),\n",
        "                                        batch_size=BatchSize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-19T13:41:43.953982Z",
          "start_time": "2019-07-19T13:21:30.087007Z"
        },
        "id": "eUHR4_ugU2vv"
      },
      "outputs": [],
      "source": [
        "# Train the model with augmented data and assess the performance\n",
        "conv_net1_aug = simple_cnn_model()\n",
        "conv_net1_aug_loss_acc_records = conv_net1_aug.fit_generator(train_aug, steps_per_epoch=len(train_aug),validation_data=test_gen, validation_steps=len(test_gen), \n",
        "                              epochs=n_epochs, verbose=1, use_multiprocessing=True, workers=2) #validation_freq=[1,2,5,10,15,20],"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-19T13:41:44.315092Z",
          "start_time": "2019-07-19T13:41:43.959330Z"
        },
        "id": "qTQc03gMU2v0"
      },
      "outputs": [],
      "source": [
        "# Plot loss and accurate and conclude\n",
        "assess_performance(conv_net1_aug_loss_acc_records)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-19T22:48:43.081318Z",
          "start_time": "2019-07-19T22:48:29.712583Z"
        },
        "id": "5RWjaZd4U2v3"
      },
      "outputs": [],
      "source": [
        "# evaluate model\n",
        "_, acc = conv_net1_aug.evaluate_generator(test_gen, steps=len(test_gen), use_multiprocessing=True, verbose=0)\n",
        "print('> %.3f' % (acc * 100.0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfOHmLLqU2v_"
      },
      "source": [
        "## 2-ConvLayers CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-19T02:36:08.395886Z",
          "start_time": "2019-07-19T02:36:08.388250Z"
        },
        "id": "TxJKHRXYU2wA"
      },
      "outputs": [],
      "source": [
        "def cnn_model():\n",
        "    '''\n",
        "      Create the 2 layers ConvNet: FirstConvLayer > FirstConvLayer > Flatten > Dense > Dense(output)\n",
        "    '''\n",
        "    num_classes = int(input(\"Enter the mumber of neuron to be activated by sigmoid function :\"))\n",
        "    # Not Implemmented\n",
        "    model = Sequential()\n",
        "    # First ConvLayer: use-ing 32 3x3-filters, 'relu' activation function, kernel_initializer='he_uniform', padding='same' with the correct input shape\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(xy_shape, xy_shape, 3)))#Conv2D with above listed parameters\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))  #MaxPooling2D with shape 2x2\n",
        "    # Second ConvLayer: use-ing 32 3x3-filters, 'relu' activation function\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu')) #Conv2D with above listed parameters\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))  #MaxPooling2D with shape 2x2\n",
        "    # Flatten followed by Dense and sigmoid Ouput Layers\n",
        "    model.add(Flatten())  # Flatten\n",
        "    model.add(Dense(128, activation=\"relu\")) # Dense with 128 neurones, activation='relu', kernel_initializer='he_uniform'\n",
        "    model.add(Dense(num_classes, activation='sigmoid'))  # Dense with 1 neuron activate by 'sigmoid' function\n",
        "    # compile model\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-19T13:16:33.370752Z",
          "start_time": "2019-07-19T13:16:28.904006Z"
        },
        "id": "-M10PDxEU2wC"
      },
      "outputs": [],
      "source": [
        "conv_net2_aug = cnn_model()\n",
        "conv_net2_aug_loss_acc_records = conv_net2_aug.fit_generator(train_aug, steps_per_epoch=len(train_aug),validation_data=test_gen, validation_steps=len(test_gen), \n",
        "                              epochs=n_epochs, verbose=1, use_multiprocessing=True, workers=2) #validation_freq=[1,2,5,10,15,20],"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-19T03:33:57.521889Z",
          "start_time": "2019-07-19T03:33:57.210208Z"
        },
        "id": "1ycAVGY7U2wF"
      },
      "outputs": [],
      "source": [
        "assess_performance(conv_net2_aug_loss_acc_records)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-19T22:46:18.246335Z",
          "start_time": "2019-07-19T22:46:18.061802Z"
        },
        "id": "sizAC7n_U2wI"
      },
      "outputs": [],
      "source": [
        "# evaluate model\n",
        "_, acc = conv_net2_aug.evaluate_generator(test_gen, steps=len(test_gen), use_multiprocessing=True, verbose=0)\n",
        "print('> %.3f' % (acc * 100.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpQz_B3yGC89"
      },
      "outputs": [],
      "source": [
        "def cnn_model1():\n",
        "    '''\n",
        "      Create the 2 layers ConvNet: FirstConvLayer > FirstConvLayer > Flatten > Dense > Dense(output)\n",
        "    '''\n",
        "    num_classes = int(input(\"Enter the mumber of neuron to be activated by sigmoid function :\"))\n",
        "    # Not Implemmented\n",
        "    model = Sequential()\n",
        "    # First ConvLayer: use-ing 32 3x3-filters, 'relu' activation function, kernel_initializer='he_uniform', padding='same' with the correct input shape\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(xy_shape, xy_shape, 3)))#Conv2D with above listed parameters\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))  #MaxPooling2D with shape 2x2\n",
        "    # Second ConvLayer: use-ing 32 3x3-filters, 'relu' activation function\n",
        "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu')) #Conv2D with above listed parameters\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))  #MaxPooling2D with shape 2x2\n",
        "    # Flatten followed by Dense and sigmoid Ouput Layers\n",
        "    model.add(Flatten())  # Flatten\n",
        "    model.add(Dense(128, activation=\"relu\")) # Dense with 128 neurones, activation='relu', kernel_initializer='he_uniform'\n",
        "    model.add(Dense(num_classes, activation='sigmoid'))  # Dense with 1 neuron activate by 'sigmoid' function\n",
        "    # compile model\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2CjnoUeGM8w"
      },
      "outputs": [],
      "source": [
        "conv_net2_aug = cnn_model1()\n",
        "conv_net2_aug_loss_acc_records = conv_net2_aug.fit_generator(train_aug, steps_per_epoch=len(train_aug),validation_data=test_gen, validation_steps=len(test_gen), \n",
        "                              epochs=n_epochs, verbose=1, use_multiprocessing=True, workers=2) #validation_freq=[1,2,5,10,15,20],"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQSUApnBGVgT"
      },
      "outputs": [],
      "source": [
        "assess_performance(conv_net2_aug_loss_acc_records)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZOX-QMeGaA5"
      },
      "outputs": [],
      "source": [
        "# evaluate model\n",
        "_, acc = conv_net2_aug.evaluate_generator(test_gen, steps=len(test_gen), use_multiprocessing=True, verbose=0)\n",
        "print('> %.3f' % (acc * 100.0))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Transfert Learning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "# define cnn model\n",
        "xy_shape3 = 224\n",
        "BatchSize3 = 64\n",
        "##using VGG16\n",
        "def deep_cnn_transfer_model():\n",
        "    model = VGG16(include_top=False, input_shape=(xy_shape3, xy_shape3, 3))\n",
        "    # mark loaded layers as not trainable\n",
        "    nb_layers = len(model.layers)\n",
        "    print('nb_layers:',nb_layers)\n",
        "    for layer in model.layers: #[:nb_layers-5]:  #model.layers[1:20]\n",
        "        layer.trainable=False\n",
        "    # add new classifier layers\n",
        "    flat1 = Flatten()(model.layers[-1].output)\n",
        "    class1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
        "    output = Dense(1, activation='sigmoid')(class1)\n",
        "    # define new model\n",
        "    model = Model(inputs=model.inputs, outputs=output)\n",
        "    # compile model\n",
        "    #opt = SGD(lr=0.001, momentum=0.9)\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "conv_deep_transfer = deep_cnn_transfer_model()\n",
        "conv_deep_transfer.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_aug = trainAug.flow_from_directory(training_path,class_mode=\"binary\",target_size=(xy_shape3, xy_shape3),\n",
        "                                         batch_size=BatchSize3)\n",
        "test_gen = dataGen.flow_from_directory(testing_path,class_mode=\"binary\",target_size=(xy_shape3, xy_shape3),\n",
        "                                        batch_size=BatchSize3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "conv_deep_transfer_loss_acc_records = conv_deep_transfer.fit_generator(train_aug, steps_per_epoch=len(train_aug),validation_data=test_gen, validation_steps=len(test_gen), \n",
        "                              epochs=n_epochs, verbose=1, use_multiprocessing=True, workers=2) #validation_freq=[1,2,5,10,15,20],"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "assess_performance(conv_deep_transfer_loss_acc_records)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# evaluate model\n",
        "_, acc = conv_deep_transfer.evaluate_generator(test_gen, steps=len(test_gen), use_multiprocessing=True, verbose=0)\n",
        "print('> %.3f' % (acc * 100.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "# define cnn model\n",
        "xy_shape3 = 224\n",
        "BatchSize3 = 64\n",
        "##using ResNet50\n",
        "def deep_cnn_transfer_model_resnet():\n",
        "    model = ResNet50(include_top=False, input_shape=(xy_shape3, xy_shape3, 3))\n",
        "    # mark loaded layers as not trainable\n",
        "    nb_layers = len(model.layers)\n",
        "    print('nb_layers:',nb_layers)\n",
        "    for layer in model.layers: #[:nb_layers-5]:  #model.layers[1:20]\n",
        "        layer.trainable=False\n",
        "    # add new classifier layers\n",
        "    flat1 = Flatten()(model.layers[-1].output)\n",
        "    class1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
        "    output = Dense(1, activation='sigmoid')(class1)\n",
        "    # define new model\n",
        "    model = Model(inputs=model.inputs, outputs=output)\n",
        "    # compile model\n",
        "    #opt = SGD(lr=0.001, momentum=0.9)\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "conv_deep_transfer_resnet = deep_cnn_transfer_model_resnet()\n",
        "conv_deep_transfer_resnet.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_aug = trainAug.flow_from_directory(training_path,class_mode=\"binary\",target_size=(xy_shape3, xy_shape3),\n",
        "                                         batch_size=BatchSize3)\n",
        "test_gen = dataGen.flow_from_directory(testing_path,class_mode=\"binary\",target_size=(xy_shape3, xy_shape3),\n",
        "                                        batch_size=BatchSize3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "conv_deep_transfer_loss_acc_records_resnet = conv_deep_transfer_resnet.fit_generator(train_aug, steps_per_epoch=len(train_aug),validation_data=test_gen, validation_steps=len(test_gen), \n",
        "                              epochs=n_epochs, verbose=1, use_multiprocessing=True, workers=2) #validation_freq=[1,2,5,10,15,20],"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def assess_performance(history):\n",
        "    pyplot.figure(figsize=(15,3))\n",
        "    # plot loss\n",
        "    pyplot.subplot(121)\n",
        "    pyplot.title('Cross Entropy Loss')\n",
        "    pyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "    pyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "    pyplot.legend()\n",
        "    # plot accuracy\n",
        "    pyplot.subplot(122)\n",
        "    pyplot.title('Classification Accuracy')\n",
        "    pyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "    pyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "    pyplot.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# evaluate model\n",
        "_, acc = conv_deep_transfer_resnet.evaluate_generator(test_gen, steps=len(test_gen), use_multiprocessing=True, verbose=0)\n",
        "print('> %.3f' % (acc * 100.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Hypeparameter tuning (batcsize = 256, optimizer=adam, epoch=20, neurons=256)\n",
        "from keras.optimizers import SGD, Adam\n",
        "xy_shape3 = 224\n",
        "BatchSize3 = 256\n",
        "##using ResNet50\n",
        "def deep_cnn_transfer_model_resnet2():\n",
        "    model = ResNet50(include_top=False, input_shape=(xy_shape3, xy_shape3, 3))\n",
        "    # mark loaded layers as not trainable\n",
        "    nb_layers = len(model.layers)\n",
        "    print('nb_layers:',nb_layers)\n",
        "    for layer in model.layers: #[:nb_layers-5]:  #model.layers[1:20]\n",
        "        layer.trainable=False\n",
        "    # add new classifier layers\n",
        "    flat1 = Flatten()(model.layers[-1].output)\n",
        "    class1 = Dense(256, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
        "    output = Dense(1, activation='sigmoid')(class1)\n",
        "    # define new model\n",
        "    model = Model(inputs=model.inputs, outputs=output)\n",
        "    # compile model\n",
        "    #opt = SGD(lr=0.001, momentum=0.9)\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "conv_deep_transfer_resnet2 = deep_cnn_transfer_model_resnet2()\n",
        "# conv_deep_transfer_resnet2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "conv_deep_transfer_loss_acc_records_resnet2 = conv_deep_transfer_resnet2.fit_generator(train_aug, steps_per_epoch=len(train_aug),validation_data=test_gen, validation_steps=len(test_gen), \n",
        "                              epochs=n_epochs, verbose=1, use_multiprocessing=True, workers=2) #validation_freq=[1,2,5,10,15,20],"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After training the different models, following are the performance results (in term of accuracy) during testing.\n",
        "\n",
        "*   conv_net1: 90.149%\n",
        "\n",
        "*   conv_net1_aug: 93.63%\n",
        "\n",
        "*   conv_net2_aug:95.81%\n",
        "\n",
        "*   conv_deep_transfer: \n",
        "** VGG16: 93.47%\n",
        "** ResNet50: 76.20%\n",
        "\n",
        "***Conclusion:*** The CNN with 2 ConvLayers performed better with an accuracy of 95% compared to others. Using pre-trained models did not improve the accuracy. When comparing the pre-trained models used for this task, VGG16 performed better than ResNet. Even after fine-tuning ResNet50 by increasing the batch size and number of neurons, the results were still lower compared to the other models."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pjnHwwTcTKhH"
      },
      "source": [
        "## Further work: Try to improve the performance by trying different strategies:\n",
        "* Hyperparameters tuning\n",
        "* Test other models\n",
        "  - eg. ResNet, VGG"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
